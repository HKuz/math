{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Algebra\n",
    "\n",
    "Sources: [Deep Learning](www.deeplearningbook.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definitions and notation:\n",
    "\n",
    "- **Scalar**: a single number, such as $s \\in \\mathbb{R}$ or $n \\in \\mathbb{N}$.\n",
    "- **Vector**: an array of numbers in order. If each element $x_i \\in \\mathbb{R}$ for vector $\\mathbf{a}$, then vector $\\mathbf{a}$ lies in set $\\mathbb{R}^n$. Vectors in machine learning are typically column vectors (shape $n \\times 1$). You can think of vectors as identifying points in space, with each element giving the coordinate along a diï¬€erent axis.\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{a} = \\sum_{i=1}^n a_i b_i\n",
    "\\end{align}\n",
    "\n",
    "- **Matrix**: 2D array of numbers, each element has two indices. A matrix $\\mathbf{A}$ with $m$ rows and $n$ columns, then $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$. Elements of a matrix are identified as $A_{i, j}$ where the subscripts identify the $i$-th row and $j$-th column for the item.\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{A} = \\begin{bmatrix}\n",
    "A_{1, 1} & A_{1, 2} \\\\\n",
    "A_{2, 1} & A_{2, 2} \n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "\n",
    "- **Tensor**: an array $\\mathsf{A}$ with more than two axes. Elements are identified by $\\mathsf{A}_{i, j, k}$.\n",
    "- **Transpose**: the transpose of a matrix is the mirror image of the matrix across the main diagonal (running down and to right):\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{A} = \\begin{bmatrix}\n",
    "A_{1, 1} & A_{1, 2} \\\\\n",
    "A_{2, 1} & A_{2, 2} \\\\\n",
    "A_{3, 1} & A_{3, 2}\n",
    "\\end{bmatrix} \\Rightarrow\n",
    "\\mathbf{A}^\\mathsf{T} = \\begin{bmatrix}\n",
    "A_{1, 1} & A_{2, 1} & A_{3, 1} \\\\\n",
    "A_{1, 2} & A_{2, 2} & A_{3, 2} \n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "\n",
    "- The **dot product** of two vectors $\\mathbf{a}$ and $\\mathbf{b}$ of the same dimensionality is defined as the sum of the element-wise products:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{a} \\cdot \\mathbf{b} = \\sum_{i=1}^n a_i b_i\n",
    "\\end{align}\n",
    "\n",
    "- **Matrix multiplication** of $A$ and $B$ only works if $A$ has the same number of columns as $B$ has rows. So if $A$ is $m \\times n$ and $B$ is $n \\times p$, the result $C$ is of shape $m \\times p$\n",
    "\n",
    "$$\n",
    "C_{i, j} = \\sum_k \\mathbf{A}_{i, k} \\mathbf{B}_{k, j}\n",
    "$$\n",
    "\n",
    "- An element-wise product, or **Hadamard product**, multiplies each element ($\\mathbf{A} \\odot \\mathbf{B}$)\n",
    "- A system of equations can be written as $\\mathbf{Ax} = \\mathbf{b}$, where $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$ is a known matrix, $\\mathbf{b} \\in \\mathbb{R}^{m}$ is a known vector, and $\\mathbf{x} \\in \\mathbb{R}^{n}$ is a vector of unknown variables to solve for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector a: [1 2 3 4]\n",
      "Vector b: [1 0 2 1]\n",
      "Dot product of a and b: 11\n"
     ]
    }
   ],
   "source": [
    "# Vectors and dot products\n",
    "a = np.array([1, 2, 3, 4]).reshape(4,)\n",
    "print('Vector a:', a)\n",
    "\n",
    "b = np.array([1, 0, 2, 1]).reshape(4,)\n",
    "print('Vector b:', b)\n",
    "\n",
    "print('Dot product of a and b:', np.dot(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A:\n",
      "[[ 5  2]\n",
      " [10  1]\n",
      " [ 0  7]]\n",
      "Matrix B:\n",
      "[[1 3]\n",
      " [0 1]]\n",
      "AB =\n",
      "[[ 5 17]\n",
      " [10 31]\n",
      " [ 0  7]]\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "A = np.array([5, 2, 10, 1, 0, 7]).reshape(3, 2)\n",
    "print('Matrix A:')\n",
    "print(A)\n",
    "\n",
    "B = np.array([1, 3, 0, 1]).reshape(2, 2)\n",
    "print('Matrix B:')\n",
    "print(B)\n",
    "\n",
    "print('AB =')\n",
    "print(np.matmul(A, B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Multiplication Properties\n",
    "\n",
    "Matrix multiplication is both distributive $\\mathbf{A}(\\mathbf{B} + \\mathbf{C}) = \\mathbf{A}\\mathbf{B} + \\mathbf{A}\\mathbf{C}$ as well as associative $\\mathbf{A}(\\mathbf{B} \\mathbf{C}) = (\\mathbf{A}\\mathbf{B}) \\mathbf{C}$.\n",
    "\n",
    "However, matrix multiplication is NOT commutative $\\mathbf{A} \\mathbf{B} \\ne \\mathbf{B} \\mathbf{A}$. That said, the dot product between two vectors is commutative: $\\mathbf{x}^{\\mathsf{T}} \\mathbf{y} = \\mathbf{y}^{\\mathsf{T}} \\mathbf{x}$.\n",
    "\n",
    "The transpose of a matrix product can be written as $\\mathbf{AB}^{\\mathsf{T}} = \\mathbf{B}^{\\mathsf{T}} \\mathbf{A}^{\\mathsf{T}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A:\n",
      "[[ 5  2]\n",
      " [10  1]\n",
      " [ 0  7]]\n",
      "Transpose of A:\n",
      "[[ 5 10  0]\n",
      " [ 2  1  7]]\n"
     ]
    }
   ],
   "source": [
    "# Transposes\n",
    "print('Matrix A:')\n",
    "print(A)\n",
    "print('Transpose of A:')\n",
    "print(A.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector a:\n",
      "Vector b:\n",
      "Tranpose of a dot b:\n",
      "11\n",
      "Tranpose of b dot a:\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "print('Vector a:')\n",
    "print('Vector b:')\n",
    "print('Tranpose of a dot b:')\n",
    "print(np.dot(a.T, b))\n",
    "print('Tranpose of b dot a:')\n",
    "print(np.dot(b.T, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A(B + C):\n",
      "[[25 39]\n",
      " [50 72]\n",
      " [ 0 14]]\n",
      "AB + AC:\n",
      "[[25 39]\n",
      " [50 72]\n",
      " [ 0 14]]\n"
     ]
    }
   ],
   "source": [
    "# Distributive property\n",
    "C = np.array([4, 4, 0, 1]).reshape(2, 2)\n",
    "print('A(B + C):')\n",
    "print(np.matmul(A, B+C))\n",
    "\n",
    "print('AB + AC:')\n",
    "print(np.matmul(A, B) + np.matmul(A, C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A(BC):\n",
      "[[20 37]\n",
      " [40 71]\n",
      " [ 0  7]]\n",
      "(AB)C:\n",
      "[[20 37]\n",
      " [40 71]\n",
      " [ 0  7]]\n"
     ]
    }
   ],
   "source": [
    "# Associative property\n",
    "print('A(BC):')\n",
    "print(np.matmul(A, np.matmul(B, C)))\n",
    "\n",
    "print('(AB)C:')\n",
    "print(np.matmul(np.matmul(A, B), C))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identity and Inverse Matrices\n",
    "\n",
    "The **identity matrix** is a matrix that does not change any vector when you multiply the vector by that matrix. The identity matrix that preserves $n$-dimensional vectors is denoted $\\mathbf{I}_n$:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{I}_n \\in \\mathbb{R}^{n \\times n} \\text{and } \\forall \\mathbf{x} \\in \\mathbb{R}^n, \\, \\mathbf{I}_n \\mathbf{x} = \\mathbf{x}\n",
    "\\end{align}\n",
    "\n",
    "The structure of an identity matrix has $1$'s along the main diagonal and zeroes for all other entries. For example:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{I}_3 = \\begin{bmatrix}\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "0 & 0 & 1 \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "\n",
    "A **matrix inverse** of $\\mathbf{A}$ is written as $\\mathbf{A}^{-1}$ and is defined so $\\mathbf{A}^{-1} \\mathbf{A} = \\mathbf{I}_n$. It's also possible to define an inverse that's multiplied on the right, such that $\\mathbf{A} \\mathbf{A}^{-1} = \\mathbf{I}_n$. For square matrices ($m = n$), the left and right inverses are the same.\n",
    "\n",
    "This is useful in theory to solve a system of linear equations $\\mathbf{Ax} = \\mathbf{b}$, where the solution is $\\mathbf{x} = \\mathbf{A}^{-1} \\mathbf{b}$. This assumes that the inverse exists, for that to happen, the equation $\\mathbf{Ax} = \\mathbf{b}$ has exactly one solution (versus no solutions or an infinite number of solutions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identity matrix (4x4):\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      "Vector a:\n",
      "[1 2 3 4]\n",
      "I_4 * a:\n",
      "[1. 2. 3. 4.]\n"
     ]
    }
   ],
   "source": [
    "I4 = np.eye(4)\n",
    "print('Identity matrix (4x4):')\n",
    "print(I4)\n",
    "\n",
    "print('Vector a:')\n",
    "print(a)\n",
    "\n",
    "print('I_4 * a:')\n",
    "print(np.matmul(I4, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Combinations and Span\n",
    "\n",
    "A **linear combination** of a set of vectors $\\{\\mathbf{v}^{(1)}, \\ldots , \\mathbf{v}^{(n)} \\}$ is given be multiplying each vector $\\mathbf{v}^{(i)}$ by a scalar and adding the results:\n",
    "\n",
    "\\begin{align}\n",
    "\\displaystyle \\sum_i = c_i \\mathbf{v}^{(i)}\n",
    "\\end{align}\n",
    "\n",
    "The **span** of a set of vectors is the set of all points obtainable by linear combination of the original vectors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
