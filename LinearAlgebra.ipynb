{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Algebra\n",
    "\n",
    "Sources: [Deep Learning](www.deeplearningbook.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definitions and notation:\n",
    "\n",
    "- **Scalar**: a single number, such as $s \\in \\mathbb{R}$ or $n \\in \\mathbb{N}$.\n",
    "- **Vector**: an array of numbers in order. If each element $x_i \\in \\mathbb{R}$ for vector $\\mathbf{a}$, then vector $\\mathbf{a}$ lies in set $\\mathbb{R}^n$. Vectors in machine learning are typically column vectors (shape $n \\times 1$). You can think of vectors as identifying points in space, with each element giving the coordinate along a diï¬€erent axis.\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{a} = \\sum_{i=1}^n a_i b_i\n",
    "\\end{align}\n",
    "\n",
    "- **Matrix**: 2D array of numbers, each element has two indices. A matrix $\\mathbf{A}$ with $m$ rows and $n$ columns, then $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$. Elements of a matrix are identified as $A_{i, j}$ where the subscripts identify the $i$-th row and $j$-th column for the item.\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{A} = \\begin{bmatrix}\n",
    "A_{1, 1} & A_{1, 2} \\\\\n",
    "A_{2, 1} & A_{2, 2} \n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "\n",
    "- **Tensor**: an array $\\mathsf{A}$ with more than two axes. Elements are identified by $\\mathsf{A}_{i, j, k}$.\n",
    "- **Transpose**: the transpose of a matrix is the mirror image of the matrix across the main diagonal (running down and to right):\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{A} = \\begin{bmatrix}\n",
    "A_{1, 1} & A_{1, 2} \\\\\n",
    "A_{2, 1} & A_{2, 2} \\\\\n",
    "A_{3, 1} & A_{3, 2}\n",
    "\\end{bmatrix} \\Rightarrow\n",
    "\\mathbf{A}^\\mathsf{T} = \\begin{bmatrix}\n",
    "A_{1, 1} & A_{2, 1} & A_{3, 1} \\\\\n",
    "A_{1, 2} & A_{2, 2} & A_{3, 2} \n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "\n",
    "- The **dot product** of two vectors $\\mathbf{a}$ and $\\mathbf{b}$ of the same dimensionality is defined as the sum of the element-wise products:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{a} \\cdot \\mathbf{b} = \\sum_{i=1}^n a_i b_i\n",
    "\\end{align}\n",
    "\n",
    "- **Matrix multiplication** of $A$ and $B$ only works if $A$ has the same number of columns as $B$ has rows. So if $A$ is $m \\times n$ and $B$ is $n \\times p$, the result $C$ is of shape $m \\times p$\n",
    "\n",
    "$$\n",
    "C_{i, j} = \\sum_k \\mathbf{A}_{i, k} \\mathbf{B}_{k, j}\n",
    "$$\n",
    "\n",
    "- An element-wise product, or **Hadamard product**, multiplies each element ($\\mathbf{A} \\odot \\mathbf{B}$)\n",
    "- A system of equations can be written as $\\mathbf{Ax} = \\mathbf{b}$, where $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$ is a known matrix, $\\mathbf{b} \\in \\mathbb{R}^{m}$ is a known vector, and $\\mathbf{x} \\in \\mathbb{R}^{n}$ is a vector of unknown variables to solve for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector a: [1 2 3 4]\n",
      "Vector b: [1 0 2 1]\n",
      "Dot product of a and b: 11\n"
     ]
    }
   ],
   "source": [
    "# Vectors and dot products\n",
    "a = np.array([1, 2, 3, 4]).reshape(4,)\n",
    "print('Vector a:', a)\n",
    "\n",
    "b = np.array([1, 0, 2, 1]).reshape(4,)\n",
    "print('Vector b:', b)\n",
    "\n",
    "print('Dot product of a and b:', np.dot(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A:\n",
      "[[ 5  2]\n",
      " [10  1]\n",
      " [ 0  7]]\n",
      "Matrix B:\n",
      "[[1 3]\n",
      " [0 1]]\n",
      "AB =\n",
      "[[ 5 17]\n",
      " [10 31]\n",
      " [ 0  7]]\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "A = np.array([5, 2, 10, 1, 0, 7]).reshape(3, 2)\n",
    "print('Matrix A:')\n",
    "print(A)\n",
    "\n",
    "B = np.array([1, 3, 0, 1]).reshape(2, 2)\n",
    "print('Matrix B:')\n",
    "print(B)\n",
    "\n",
    "print('AB =')\n",
    "print(np.matmul(A, B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Properties and Identities\n",
    "\n",
    "Matrix multiplication is both distributive $\\mathbf{A}(\\mathbf{B} + \\mathbf{C}) = \\mathbf{A}\\mathbf{B} + \\mathbf{A}\\mathbf{C}$ as well as associative $\\mathbf{A}(\\mathbf{B} \\mathbf{C}) = (\\mathbf{A}\\mathbf{B}) \\mathbf{C}$.\n",
    "\n",
    "However, matrix multiplication is NOT commutative $\\mathbf{A} \\mathbf{B} \\ne \\mathbf{B} \\mathbf{A}$. That said, the dot product between two vectors is commutative: $\\mathbf{x}^{\\mathsf{T}} \\mathbf{y} = \\mathbf{y}^{\\mathsf{T}} \\mathbf{x}$.\n",
    "\n",
    "The transpose of a matrix product can be written as $\\mathbf{AB}^{\\mathsf{T}} = \\mathbf{B}^{\\mathsf{T}} \\mathbf{A}^{\\mathsf{T}}$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
